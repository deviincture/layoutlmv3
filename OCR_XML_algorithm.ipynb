{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deviincture/layoutlmv3/blob/main/OCR_XML_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPfpzV52SWR7"
      },
      "outputs": [],
      "source": [
        "!pip install transformers@git+https://github.com/monuminu/transformers.git &> /dev/null\n",
        "!pip install seqeval &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvLa6N53S2-F",
        "outputId": "92f986d8-13de-4ebc-8ff9-a65eb1df4085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4HaeuK4Tj7Y"
      },
      "outputs": [],
      "source": [
        "!pip install pyyaml>=5.1, bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE9oAeFylVfb"
      },
      "outputs": [],
      "source": [
        "!pip install beautifulsoup4 &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8mW5MGQlZYz"
      },
      "outputs": [],
      "source": [
        "!pip install lxml  &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFoljKrtix_v"
      },
      "outputs": [],
      "source": [
        "!pip install PyPDF2 &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import LayoutLMv2Tokenizer, LayoutLMv2ForTokenClassification, LayoutLMv2Config\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "def normalize_box(box, width, height):\n",
        "    width = int(width)\n",
        "    height = int(height)\n",
        "    return [\n",
        "         int(1000 * (box[0] / width)),\n",
        "         int(1000 * (box[1] / height)),\n",
        "         int(1000 * (box[2] / width)),\n",
        "         int(1000 * (box[3] / height)),\n",
        "     ]\n",
        "\n",
        "def resize_and_align_bounding_box(bbox, original_image, target_size):\n",
        "    x_, y_ = original_image.size\n",
        "    x_scale = target_size / x_\n",
        "    y_scale = target_size / y_\n",
        "    origLeft, origTop, origRight, origBottom = tuple(bbox)\n",
        "    x = int(np.round(origLeft * x_scale))\n",
        "    y = int(np.round(origTop * y_scale))\n",
        "    xmax = int(np.round(origRight * x_scale))\n",
        "    ymax = int(np.round(origBottom * y_scale))\n",
        "    return [x-0.5, y-0.5, xmax+0.5, ymax+0.5]\n",
        "\n",
        "class InvoiceDataSet(Dataset):\n",
        "    \"\"\"LayoutLM dataset with visual features.\"\"\"\n",
        "\n",
        "    def __init__(self, df, tokenizer, max_length, target_size, train=True):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_length\n",
        "        self.target_size = target_size\n",
        "        self.pad_token_box = [0, 0, 0, 0]\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.df.iloc[idx,:].to_dict()\n",
        "        #base_path = data_config.base_image_path\n",
        "        original_image = Image.open(os.path.join(base_path , item[\"imageFilename\"])).convert(\"RGB\")\n",
        "        # resize to target size (to be provided to the pre-trained backbone)\n",
        "        resized_image = original_image.resize((self.target_size, self.target_size))\n",
        "        # first, read in annotations at word-level (words, bounding boxes, labels)\n",
        "        words = item[\"words\"]\n",
        "        unnormalized_word_boxes = item[\"bbox\"]\n",
        "        word_labels = item[\"label\"]\n",
        "        width = item[\"imageWidth\"]\n",
        "        height = item[\"imageHeight\"]\n",
        "        normalized_word_boxes = [normalize_box(bbox, width, height) for bbox in unnormalized_word_boxes]\n",
        "        assert len(words) == len(normalized_word_boxes)\n",
        "\n",
        "        # next, transform to token-level (input_ids, attention_mask, token_type_ids, bbox, labels)\n",
        "        token_boxes = []\n",
        "        unnormalized_token_boxes = []\n",
        "        token_labels = []\n",
        "        for word, unnormalized_box, box, label in zip(words, unnormalized_word_boxes, normalized_word_boxes, word_labels):\n",
        "            word_tokens = self.tokenizer.tokenize(word)\n",
        "            unnormalized_token_boxes.extend(unnormalized_box for _ in range(len(word_tokens)))\n",
        "            token_boxes.extend(box for _ in range(len(word_tokens)))\n",
        "            # label first token as B-label (beginning), label all remaining tokens as I-label (inside)\n",
        "            for i in range(len(word_tokens)):\n",
        "                if i == 0:\n",
        "                    token_labels.extend(['B-' + label])\n",
        "                else:\n",
        "                    token_labels.extend(['I-' + label])\n",
        "\n",
        "        # Truncation of token_boxes + token_labels\n",
        "        special_tokens_count = 2\n",
        "        if len(token_boxes) > self.max_seq_length - special_tokens_count:\n",
        "            token_boxes = token_boxes[: (self.max_seq_length - special_tokens_count)]\n",
        "            unnormalized_token_boxes = unnormalized_token_boxes[: (self.max_seq_length - special_tokens_count)]\n",
        "            token_labels = token_labels[: (self.max_seq_length - special_tokens_count)]\n",
        "\n",
        "        # add bounding boxes and labels of cls + sep tokens\n",
        "        token_boxes = [self.pad_token_box] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
        "        unnormalized_token_boxes = [self.pad_token_box] + unnormalized_token_boxes + [[1000, 1000, 1000, 1000]]\n",
        "        token_labels = [-100] + token_labels + [-100]\n",
        "\n",
        "        encoding = self.tokenizer(' '.join(words), padding='max_length', truncation=True)\n",
        "        # Padding of token_boxes up the bounding boxes to the sequence length.\n",
        "        input_ids = self.tokenizer(' '.join(words), truncation=True)[\"input_ids\"]\n",
        "        padding_length = self.max_seq_length - len(input_ids)\n",
        "        token_boxes += [self.pad_token_box] * padding_length\n",
        "        unnormalized_token_boxes += [self.pad_token_box] * padding_length\n",
        "        token_labels += [-100] * padding_length\n",
        "        encoding['bbox'] = token_boxes\n",
        "        encoding['labels'] = token_labels\n",
        "\n",
        "        assert len(encoding['input_ids']) == self.max_seq_length\n",
        "        assert len(encoding['attention_mask']) == self.max_seq_length\n",
        "        assert len(encoding['token_type_ids']) == self.max_seq_length\n",
        "        assert len(encoding['bbox']) == self.max_seq_length\n",
        "        assert len(encoding['labels']) == self.max_seq_length\n",
        "\n",
        "        encoding['resized_image'] = ToTensor()(resized_image)\n",
        "        # rescale and align the bounding boxes to match the resized image size (typically 224x224)\n",
        "        encoding['resized_and_aligned_bounding_boxes'] = [resize_and_align_bounding_box(bbox, original_image, self.target_size) for bbox in unnormalized_token_boxes]\n",
        "        #encoding['unnormalized_token_boxes'] = unnormalized_token_boxes\n",
        "\n",
        "        # finally, convert everything to PyTorch tensors\n",
        "        for k,v in encoding.items():\n",
        "            if k == 'labels':\n",
        "                label_indices = []\n",
        "                # convert labels from string to indices\n",
        "                for label in encoding[k]:\n",
        "                    if label != -100:\n",
        "                        label_indices.append(data_config.label2id[label])\n",
        "                    else:\n",
        "                        label_indices.append(label)\n",
        "                encoding[k] = label_indices\n",
        "            encoding[k] = torch.as_tensor(encoding[k])\n",
        "        return encoding"
      ],
      "metadata": {
        "id": "fwk72PlgCK_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btODdKc3ikZm"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def pdf_to_text(pdf_path):\n",
        "    pdf_file = open(pdf_path, 'rb')\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text = ''\n",
        "    for page_num in range(len(pdf_reader.pages)):\n",
        "        page = pdf_reader.pages[page_num]\n",
        "        text += page.extract_text()\n",
        "    pdf_file.close()\n",
        "    return text\n",
        "\n",
        "def text_to_xml(text, xml_path):\n",
        "    with open(xml_path, 'w') as xml_file:\n",
        "        xml_file.write('<root>\\n')\n",
        "        lines = text.split('\\n')\n",
        "        for line in lines:\n",
        "            xml_file.write(f'  <line>{line}</line>\\n')\n",
        "        xml_file.write('</root>')\n",
        "\n",
        "# pdf_path = '/content/dov.pdf'\n",
        "# xml_path = '/content/drive/My Drive/ColabNotebooks/xml_file.xml'\n",
        "\n",
        "# pdf_text = pdf_to_text(pdf_path)\n",
        "# text_to_xml(pdf_text, xml_path)\n",
        "\n",
        "# print(f'PDF content has been converted to XML and saved to {xml_path}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSaHc3lSlDru"
      },
      "outputs": [],
      "source": [
        "#test\n",
        "from bs4 import BeautifulSoup\n",
        "# Reading the data inside the xml file to a variable under the name data\n",
        "with open('/content/drive/MyDrive/ColabNotebooks/xml_file.xml', 'r') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Passing the stored data inside the beautifulsoup parser, storing the returned object\n",
        "Bs_data = BeautifulSoup(data, \"xml\")\n",
        "# print(Bs_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BS2d9Q7zssdy"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from xml.etree import ElementTree as ET\n",
        "files_tif = glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*tif\")\n",
        "files_gt_xml= glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*_gt.xml\")\n",
        "files_ocr_xml= glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*_ocr.xml\")\n",
        "# print(\"number of files: {}\".format(len(files)))\n",
        "tif_files=[]\n",
        "gt_xml_files=[]\n",
        "ocr_xml_files=[]\n",
        "for file in files_tif:\n",
        "  # print(file)\n",
        "  if file.endswith(\".tif\"):\n",
        "    tif_files.append(file)\n",
        "for file in files_gt_xml:\n",
        "  gt_xml_files.append(file)\n",
        "for file in files_ocr_xml:\n",
        "  ocr_xml_files.append(file)\n",
        "\n",
        "\n",
        "def get_get_bbox(bbox):\n",
        "    items = bbox.split(\",\")\n",
        "    x1 = int(float(items[0]))\n",
        "    y1 = int(float(items[1].split(\" \")[0]))\n",
        "    x2 = int(float(items[1].split(\" \")[1]))\n",
        "    y2 = int(float(items[-1]))\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "# get_words_bbox(gt_xml_files)\n",
        "\n",
        "word_list = []\n",
        "for xml_file_path in ocr_xml_files:\n",
        "  with open(xml_file_path, encoding=\"utf8\") as f:\n",
        "        xml_data = f.read()\n",
        "  soup = BeautifulSoup(xml_data, 'xml')\n",
        "  page = soup.find_all('Page')\n",
        "  words = soup.find_all('Word')\n",
        "  page_attrs = page[0].attrs\n",
        "  # print(page_attrs)\n",
        "\n",
        "\n",
        "  for word in words:\n",
        "      word_dict = {}\n",
        "      for content in word.contents:\n",
        "            word_dict.update({\"text\": word.find(\"Unicode\").get_text()})\n",
        "            word_dict.update({\"Points\": word.find(\"Coords\")['points']})\n",
        "            if isinstance(content, ET.Element):\n",
        "                word_dict.update(content.attrs)\n",
        "            word_dict[\"bbox\"] = get_get_bbox(word_dict.get('Points', ''))\n",
        "            word_dict.pop(\"Points\")\n",
        "            word_list.append(word_dict)\n",
        "  # print(page_attrs)\n",
        "  # print(sorted(word_list, key=lambda x: [x[\"bbox\"][1], x[\"bbox\"][0]]))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ7tFD6MNke-"
      },
      "outputs": [],
      "source": [
        "# from bs4 import BeautifulSoup\n",
        "# from xml.etree import ElementTree as ET\n",
        "\n",
        "# files_tif = glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*tif\")\n",
        "# files_gt_xml= glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*_gt.xml\")\n",
        "# files_ocr_xml= glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*_ocr.xml\")\n",
        "# print(\"number of files: {}\".format(len(files)))\n",
        "# tif_files=[]\n",
        "# gt_xml_files=[]\n",
        "# ocr_xml_files=[]\n",
        "# for file in files_tif:\n",
        "#   # print(file)\n",
        "#   if file.endswith(\".tif\"):\n",
        "#     tif_files.append(file)\n",
        "# for file in files_gt_xml:\n",
        "#   gt_xml_files.append(file)\n",
        "# for file in files_ocr_xml:\n",
        "#   ocr_xml_files.append(file)\n",
        "\n",
        "\n",
        "def get_bbox(bbox):\n",
        "    items = bbox.split(\",\")\n",
        "    x1 = int(float(items[0]))\n",
        "    y1 = int(float(items[1].split(\" \")[0]))\n",
        "    x2 = int(float(items[1].split(\" \")[1]))\n",
        "    y2 = int(float(items[-1]))\n",
        "    return [x1, y1, x2, y2]\n",
        "\n",
        "\n",
        "def get_words_bbox(ocr_xml_files):\n",
        "    word_list = []\n",
        "    for xml_file_path in ocr_xml_files:\n",
        "        with open(xml_file_path, encoding=\"utf8\") as f:\n",
        "            xml_data = f.read()\n",
        "        soup = BeautifulSoup(xml_data, 'xml')\n",
        "        page = soup.find_all('Page')\n",
        "        words = soup.find_all('Word')\n",
        "        page_attrs = page[0].attrs\n",
        "        page_attrs\n",
        "\n",
        "        for word in words:\n",
        "            word_dict = {}\n",
        "            for content in word.contents:\n",
        "                word_dict.update({\"text\": word.find(\"Unicode\").get_text()})\n",
        "                word_dict.update({\"Points\": word.find(\"Coords\")['points']})\n",
        "                if isinstance(content, ET.Element):\n",
        "                    word_dict.update(content.attrs)\n",
        "                word_dict[\"bbox\"] = get_bbox(word_dict.get('Points', ''))\n",
        "                word_dict.pop(\"Points\")\n",
        "                word_list.append(word_dict)\n",
        "        # print(page_attrs)\n",
        "        # print(sorted(word_list, key=lambda x: [x[\"bbox\"][1], x[\"bbox\"][0]]))\n",
        "\n",
        "    return page_attrs, sorted(word_list, key=lambda x: [x[\"bbox\"][1], x[\"bbox\"][0]])\n",
        "    # return sorted(word_list)\n",
        "\n",
        "# # Example usage:\n",
        "# gt_xml_files = [\"path/to/your/xml/file1.xml\", \"path/to/your/xml/file2.xml\"]\n",
        "# page_attrs, sorted_word_list = get_words_bbox(ocr_xml_files)\n",
        "# print(\"Page Attributes:\", page_attrs)\n",
        "# print(\"Sorted Word List:\", sorted_word_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ico2rttPUpY"
      },
      "outputs": [],
      "source": [
        "def get_label_bbox(gt_xml_files):\n",
        "  for gt_xml_path in gt_xml_files:\n",
        "    with open(gt_xml_path, encoding=\"utf8\")as f:\n",
        "        xml_data = f.read()\n",
        "    soup = BeautifulSoup(xml_data,'xml')\n",
        "    word_list = []\n",
        "    words = soup.find_all('TextRegion')\n",
        "\n",
        "    word_list = []\n",
        "    for word in words:\n",
        "        word_dict = {}\n",
        "        # word_dict.update({\"Points\": word.find(\"Coords\")['points']})\n",
        "        for content in word.contents:\n",
        "            if isinstance(content,element.Tag):\n",
        "                word_dict.update(content.attrs)\n",
        "        word_dict[\"bbox\"] = get_bbox(word_dict[\"points\"])\n",
        "        word_dict.pop(\"points\")\n",
        "        word_list.append(word_dict)\n",
        "    return sorted(word_list, key=lambda x : [x[\"bbox\"][1], x[\"bbox\"][0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erDJYQxMTY8O"
      },
      "outputs": [],
      "source": [
        "  #test\n",
        "\n",
        "  from bs4 import BeautifulSoup, element\n",
        "  for gt_xml_path in gt_xml_files:\n",
        "    with open(gt_xml_path, encoding=\"utf8\")as f:\n",
        "        xml_data = f.read()\n",
        "    soup = BeautifulSoup(xml_data,'xml')\n",
        "    word_list = []\n",
        "    words = soup.find_all('TextRegion')\n",
        "    # print(words)\n",
        "\n",
        "    word_list = []\n",
        "    for word in words:\n",
        "        # print(word)\n",
        "        word_dict = {}\n",
        "        # word_dict.update({\"Points\": word.find(\"Coords\")['points']})\n",
        "        for content in word.contents:\n",
        "            if isinstance(content,element.Tag):\n",
        "                word_dict.update(content.attrs)\n",
        "        # print(word_dict)\n",
        "        word_dict[\"bbox\"] = get_bbox(word_dict[\"points\"])\n",
        "        word_dict.pop(\"points\")\n",
        "        word_list.append(word_dict)\n",
        "    # print(sorted(word_list, key=lambda x : [x[\"bbox\"][1], x[\"bbox\"][0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7X_YxDRVn9K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def is_word_bbox_in_label_bbox(word_bbox, label_bbox):\n",
        "    x1_w,y1_w,x2_w,y2_w = word_bbox\n",
        "    x1_l,y1_l,x2_l,y2_l = label_bbox\n",
        "    if x1_w > x1_l and x2_w < x2_l and y1_w > y1_l and y2_w < y2_l:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def assign_lable_to_word(words_bbox_list, word_label_list):\n",
        "    df_label = pd.DataFrame(word_label_list)\n",
        "    df_words = pd.DataFrame(words_bbox_list)\n",
        "    lst_output = []\n",
        "    for index_word, row_word in df_words.iterrows():\n",
        "        for index_label, row_label in df_label.iterrows():\n",
        "            if is_word_bbox_in_label_bbox(row_word[\"bbox\"], row_label[\"bbox\"]):\n",
        "                row_dict = row_word.to_dict()\n",
        "                row_dict[\"label\"] = row_label[\"value\"]\n",
        "                lst_output.append(row_dict)\n",
        "    return pd.DataFrame(lst_output)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "files_tif = glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*tif\")\n",
        "files_gt_xml= glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*_gt.xml\")\n",
        "files_ocr_xml= glob.glob(f\"/content/drive/MyDrive/ImageAndXML_Data/*_ocr.xml\")\n",
        "# print(\"number of files: {}\".format(len(files)))\n",
        "tif_files=[]\n",
        "gt_xml_files=[]\n",
        "ocr_xml_files=[]\n",
        "for file in files_tif:\n",
        "  # print(file)\n",
        "  if file.endswith(\".tif\"):\n",
        "    tif_files.append(file)\n",
        "for file in files_gt_xml:\n",
        "  gt_xml_files.append(file)\n",
        "for file in files_ocr_xml:\n",
        "  ocr_xml_files.append(file)\n",
        "\n",
        "lst_output = []\n",
        "page_attrs, words_bbox_list = get_words_bbox(ocr_xml_files)\n",
        "word_label_list = get_label_bbox(gt_xml_files)\n",
        "df_word_lable = assign_lable_to_word(words_bbox_list, word_label_list)\n",
        "page_attrs.update({\"words\" : df_word_lable.text.tolist(), \"bbox\" : df_word_lable.bbox.tolist(), \"label\" : df_word_lable.label.tolist()})\n",
        "lst_output.append(page_attrs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQXNMUS6mivf"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(lst_output)[[\"imageFilename\",\"imageHeight\", \"imageWidth\", \"words\", \"bbox\", \"label\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiRclCRvnKdP"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWFZDdaRnLbP"
      },
      "outputs": [],
      "source": [
        "df.to_pickle(\"/content/data.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cec1hZadocJ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "68b3a16b-656d-49a2-954a-db259d161d48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               imageFilename imageHeight imageWidth  \\\n",
              "0  2023591606_2023591608.tif        1000        777   \n",
              "\n",
              "                                               words  \\\n",
              "0  [3/, 3/, 3/, 3/, 3/, 3, 3, 3, 3, 3, y, y, y, y...   \n",
              "\n",
              "                                                bbox  \\\n",
              "0  [[686, 17, 700, 27], [686, 17, 700, 27], [686,...   \n",
              "\n",
              "                                               label  \n",
              "0  [invoice_info, invoice_info, invoice_info, inv...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b105e990-49ed-4459-be41-6d4454b50f50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imageFilename</th>\n",
              "      <th>imageHeight</th>\n",
              "      <th>imageWidth</th>\n",
              "      <th>words</th>\n",
              "      <th>bbox</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023591606_2023591608.tif</td>\n",
              "      <td>1000</td>\n",
              "      <td>777</td>\n",
              "      <td>[3/, 3/, 3/, 3/, 3/, 3, 3, 3, 3, 3, y, y, y, y...</td>\n",
              "      <td>[[686, 17, 700, 27], [686, 17, 700, 27], [686,...</td>\n",
              "      <td>[invoice_info, invoice_info, invoice_info, inv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b105e990-49ed-4459-be41-6d4454b50f50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b105e990-49ed-4459-be41-6d4454b50f50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b105e990-49ed-4459-be41-6d4454b50f50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\n",
        "data = pd.read_pickle(\"/content/data.pkl\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxTo827cESsN",
        "outputId": "6201478f-3e29-4bb9-e5bf-b2748ead4058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_sqglNJDrb4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class data_config:\n",
        "    labels = np.unique([item for sublist in data.label for item in sublist]).tolist()\n",
        "    labels = sum([[\"B-\" + item, \"I-\" + item] for item in np.unique(labels)], [])\n",
        "    num_labels = len(labels)\n",
        "    id2label = {v: k for v, k in enumerate(labels)}\n",
        "    label2id = {k: v for v, k in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObPUQHqO6ULG",
        "outputId": "d64be57f-6d12-480d-f9e6-6e47fb300714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -U torch torchvision\n",
        "\n",
        "# Install pycocotools\n",
        "!pip install cython\n",
        "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7-mlZqGy8zNZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "404ed214-0f0f-4e95-b4c3-ba5d7f407e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Collecting torch\n",
            "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/torchvision/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torchvision\n",
            "  Downloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m861.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/nvidia-cublas-cu12/\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.1.1 torchvision-0.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (3.0.6)\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-xhr9fmji\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-xhr9fmji\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (67.7.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.0.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools==2.0) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=375525 sha256=8001a61cf1c15710688b1dcf6e62602fbdde4ae48a43b7022fc9c090079f2e2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sbcz5gy2/wheels/39/61/b4/480fbddb4d3d6bc34083e7397bc6f5d1381f79acc68e9f3511\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.7\n",
            "    Uninstalling pycocotools-2.0.7:\n",
            "      Successfully uninstalled pycocotools-2.0.7\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Detectron2\n",
        "!git clone https://github.com/facebookresearch/detectron2.git\n",
        "!pip install -e detectron2"
      ],
      "metadata": {
        "id": "olKILbpjAK-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830f5638-965d-46fd-b147-b8dd9377b476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 15285, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 15285 (delta 2), reused 5 (delta 0), pack-reused 15275\u001b[K\n",
            "Receiving objects: 100% (15285/15285), 6.18 MiB | 6.68 MiB/s, done.\n",
            "Resolving deltas: 100% (11117/11117), done.\n",
            "Obtaining file:///content/detectron2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Collecting pycocotools>=2.0.2 (from detectron2==0.6)\n",
            "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Collecting yacs>=0.1.8 (from detectron2==0.6)\n",
            "  Using cached yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.14.1)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n",
            "  Using cached fvcore-0.1.5.post20221221-py3-none-any.whl\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n",
            "  Using cached iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n",
            "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Collecting hydra-core>=1.1 (from detectron2==0.6)\n",
            "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Collecting black (from detectron2==0.6)\n",
            "  Using cached black-23.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n",
            "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n",
            "  Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n",
            "  Using cached pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, pycocotools, fvcore, detectron2\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "  Running setup.py develop for detectron2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 449, in run\n",
            "    installed = install_given_reqs(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/__init__.py\", line 72, in install_given_reqs\n",
            "    requirement.install(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 783, in install\n",
            "    install_editable_legacy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/install/editable_legacy.py\", line 42, in install_editable\n",
            "    call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 168, in emit\n",
            "    message = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 120, in format\n",
            "    formatted = \"\".join([prefix + line for line in formatted.splitlines(True)])\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0qf-nCH6xBR"
      },
      "outputs": [],
      "source": [
        "# !python -m pip install pyyaml==5.1\n",
        "\n",
        "# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n",
        "# !git clone 'https://github.com/facebookresearch/detectron2'\n",
        "# dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "# !python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "# sys.path.insert(0, os.path.abspath('./detectron2'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "dRPj-HlMfplw",
        "outputId": "1ba58e7e-c496-4fc8-9b7e-a131f22ce634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "torch:  2.1 ; cuda:  cu118\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-aec00e2cd8ab>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mCUDA_VERSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTORCH_VERSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"; cuda: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDA_VERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detectron2:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'detectron2' has no attribute '__version__'"
          ]
        }
      ],
      "source": [
        "import sys, os, distutils.core\n",
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2"
      ],
      "metadata": {
        "id": "ji8EXkHbAWAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH6MaMFrfs_L"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Nx0Nk86uAsYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bokx3Lae7X3f"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)\n",
        "from transformers import LayoutLMv2Config, LayoutLMv2Tokenizer, LayoutLMv2ForTokenClassification\n",
        "\n",
        "\n",
        "\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'microsoft/layoutlmv2-base-uncased'\n",
        "config = LayoutLMv2Config.from_pretrained(model_path, num_labels=data_config.num_labels, id2label = data_config.id2label, label2id = data_config.label2id)\n",
        "tokenizer = LayoutLMv2Tokenizer.from_pretrained(model_path)\n",
        "model = LayoutLMv2ForTokenClassification.from_pretrained(model_path, config = config)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "7M3XwWnyAvru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bw50eMFO5ruH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, valid = train_test_split(df, test_size = 0.2)\n",
        "\n",
        "train_dataset = InvoiceDataSet(df = train, tokenizer = tokenizer, max_length = 512, target_size = 224, train=True)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=5)\n",
        "\n",
        "valid_dataset = InvoiceDataSet(df = valid, tokenizer = tokenizer, max_length = 512, target_size = 224, train=False)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-KIw6Lp5tGz"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "from seqeval.metrics import (\n",
        "    classification_report,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "import torch\n",
        "\n",
        "def train_fn(train_dataloader, model, optimizer):\n",
        "    tk0 = tqdm(train_dataloader, total = len(train_dataloader))\n",
        "    for bi, batch in enumerate(tk0):\n",
        "        input_ids=batch['input_ids'].to(device)\n",
        "        bbox=batch['bbox'].to(device)\n",
        "        attention_mask=batch['attention_mask'].to(device)\n",
        "        token_type_ids=batch['token_type_ids'].to(device)\n",
        "        labels=batch['labels'].to(device)\n",
        "        resized_images = batch['resized_image'].to(device)\n",
        "        resized_and_aligned_bounding_boxes = batch['resized_and_aligned_bounding_boxes'].to(device)\n",
        "        outputs = model(image = resized_images,input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids,labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "def eval_fn(eval_dataloader, model):\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    out_label_ids = None\n",
        "    model.eval()\n",
        "    tk0 = tqdm(eval_dataloader, total = len(eval_dataloader))\n",
        "    for bi, batch in enumerate(tk0):\n",
        "        with torch.no_grad():\n",
        "            input_ids=batch['input_ids'].to(device)\n",
        "            bbox=batch['bbox'].to(device)\n",
        "            attention_mask=batch['attention_mask'].to(device)\n",
        "            token_type_ids=batch['token_type_ids'].to(device)\n",
        "            labels=batch['labels'].to(device)\n",
        "            resized_images = batch['resized_image'].to(device)\n",
        "            resized_and_aligned_bounding_boxes = batch['resized_and_aligned_bounding_boxes'].to(device)\n",
        "            outputs = model(image = resized_images,input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids,labels=labels)\n",
        "            tmp_eval_loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "            eval_loss += tmp_eval_loss.item()\n",
        "            nb_eval_steps += 1\n",
        "            if preds is None:\n",
        "                preds = logits.detach().cpu().numpy()\n",
        "                out_label_ids = labels.detach().cpu().numpy()\n",
        "            else:\n",
        "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
        "                out_label_ids = np.append(\n",
        "                    out_label_ids, labels.detach().cpu().numpy(), axis=0\n",
        "                )\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    preds = np.argmax(preds, axis=2)\n",
        "    out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "    preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
        "    for i in range(out_label_ids.shape[0]):\n",
        "        for j in range(out_label_ids.shape[1]):\n",
        "            if out_label_ids[i, j] != -100:\n",
        "                out_label_list[i].append(config.id2label[out_label_ids[i][j]])\n",
        "                preds_list[i].append(config.id2label[preds[i][j]])\n",
        "\n",
        "    results = {\n",
        "        \"loss\": eval_loss,\n",
        "        \"precision\": precision_score(out_label_list, preds_list),\n",
        "        \"recall\": recall_score(out_label_list, preds_list),\n",
        "        \"f1\": f1_score(out_label_list, preds_list),\n",
        "    }\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gti3Dzj3guNx"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH =\"/kaggle/working/pytorch_model.bin\"\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "global_step = 0\n",
        "best_f1_score = 0\n",
        "for epoch in range(5):\n",
        "    train_fn(train_dataloader, model, optimizer)\n",
        "    current_f1_score = eval_fn(valid_dataloader, model)\n",
        "    if current_f1_score[\"f1\"] > best_f1_score:\n",
        "        torch.save(model.state_dict(), MODEL_PATH)\n",
        "        best_f1_score = current_f1_score[\"f1\"]\n",
        "    print(\"best_f1_score :\", best_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7Nrl61vmrfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V0cP806ImsFY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZjVMYEhcUfWlJeyJTMgMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}